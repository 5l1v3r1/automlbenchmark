---
project_repository: https://github.com/seb-h2o/automlbenchmark
input_dir: ~/.openml/cache
output_dir: results
script:     # set by runbenchmark.py

max_parallel_jobs: 5

frameworks:
  definition_file: resources/frameworks.yaml

benchmarks:
  definition_dir: resources/benchmarks
  defaults:
    folds: 1
    max_runtime_seconds: 600
    cores: 1
    max_mem_size_mb: 2048

openml:
  apikey: c1994bdb7ecb3c6f3c8f3b35f4b47f1f

docker:
  image_defaults:
    author: automlbenchmark
    image:    # set by docker.py based on framework name, lowercase
    tag: latest

aws:
  region: ''      # read from ~/.aws/config by default
  iam:
    role_name: AutomlBenchmarkRole
    s3_policy_name: AutomlBenchmarkS3Policy
    instance_profile_name: AutomlBenchmarkProfile
  s3:
    bucket: automl-benchmark
    temporary: false
    root_key: ec2/
  ec2:
    terminate_instances: true
    instance_type: m5.large
    subnet_id: ''
    regions:
      us-east-1:
        ami: ami-0797482d7f93b830c
      us-west-1:
        ami: ami-0f27f14c7e0fffda9
      eu-west-1:
        ami: ami-0615f1e34f8d36362
      eu-central-1:
        ami: ami-0bdf93799014acdc4
        description: Ubuntu Server 18.04 LTS (HVM), EBS General Purpose (SSD) VolumeType
  max_timeout_seconds: 21600
  overhead_time_seconds: 900
  query_frequency_seconds: 15
  use_docker: true      # if true, ec2 instances will run benchmark tasks in docker image, otherwise it will run in local mode after cloning project_repository

