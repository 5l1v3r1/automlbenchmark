---
layout: category
title: Paper
sidebar_sort_order: 9
---
[PDF](https://www.automl.org/wp-content/uploads/2019/06/automlws2019_Paper45.pdf) \| [arXiv](https://arxiv.org/abs/1907.00909) \| <details><summary>[BibTeX]()</summary>
<p>
```
@article{amlb2019,
  title={An Open Source AutoML Benchmark},
  author={Gijsbers, P. and LeDell, E. and Porier, S. and Thomas, J. and Bischl, B. and Vanschoren, J.},
  journal={arXiv preprint arXiv:1907.00909 [cs.LG]},
  url={https://arxiv.org/abs/1907.00909},
  note={Accepted at AutoML Workshop at ICML 2019},
  year={2019}
}
```
</p>
</details>

> First look of the benchmark submitted to [AutoML Workshop at ICML 2019](https://sites.google.com/view/automl2019icml).

**abstract:** In recent years, an active field of research has developed around automated machine learning(AutoML). 
Unfortunately,  comparing  different  AutoML  systems  is  hard  and  often  done in correctly. 
We introduce an open, ongoing, and extensible benchmark framework which follows best practices and avoids common mistakes.
The framework is open-source, uses public datasets and has a website with up-to-date results.
We use the framework to conduct a thorough comparison of 4 AutoML systems across 39 datasets and analyze the results.

---

